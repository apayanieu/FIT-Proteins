{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5977c719",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a173772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.sparse import load_npz, vstack\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8abdb",
   "metadata": {},
   "source": [
    "## 2. File Path Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb668d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All required files found\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../../../data/processed\")\n",
    "\n",
    "def ensure_exists(path):\n",
    "    \"\"\"Check file existence and raise a clear error if missing.\"\"\"\n",
    "    if not Path(path).exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing required file: {path!s}. \"\n",
    "            \"Place it under data/processed or update the path.\"\n",
    "        )\n",
    "\n",
    "# Pre-split ECFP files (all in the same folder)\n",
    "X_train_in_fp = DATA_DIR / \"X_train_in_ecfp.npz\"\n",
    "y_train_in_fp = DATA_DIR / \"y_train_in.npy\"\n",
    "\n",
    "X_val_ood_fp  = DATA_DIR / \"X_val_ood_ecfp.npz\"\n",
    "y_val_ood_fp  = DATA_DIR / \"y_val_ood.npy\"\n",
    "\n",
    "X_test_ood_fp = DATA_DIR / \"X_test_ood_ecfp.npz\"\n",
    "y_test_ood_fp = DATA_DIR / \"y_test_ood.npy\"\n",
    "\n",
    "for p in (X_train_in_fp, y_train_in_fp,\n",
    "          X_val_ood_fp,  y_val_ood_fp,\n",
    "          X_test_ood_fp, y_test_ood_fp):\n",
    "    ensure_exists(p)\n",
    "\n",
    "print(\"✓ All required files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b83ac24",
   "metadata": {},
   "source": [
    "## 3. Load Pre-Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "713715fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_in shape: (34819, 2048) | Positives: 119\n",
      "Val_ood  shape: (7268, 2048) | Positives: 30\n",
      "Test_ood shape: (7913, 2048) | Positives: 120\n"
     ]
    }
   ],
   "source": [
    "X_tr   = load_npz(X_train_in_fp)   # train_in fingerprints\n",
    "y_tr   = np.load(y_train_in_fp)\n",
    "\n",
    "X_val  = load_npz(X_val_ood_fp)    # val_ood fingerprints\n",
    "y_val  = np.load(y_val_ood_fp)\n",
    "\n",
    "X_test = load_npz(X_test_ood_fp)   # test_ood fingerprints\n",
    "y_test = np.load(y_test_ood_fp)\n",
    "\n",
    "print(\"Train_in shape:\", X_tr.shape,  \"| Positives:\", int(y_tr.sum()))\n",
    "print(\"Val_ood  shape:\", X_val.shape, \"| Positives:\", int(y_val.sum()))\n",
    "print(\"Test_ood shape:\", X_test.shape,\"| Positives:\", int(y_test.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b5dc7",
   "metadata": {},
   "source": [
    "## 4. Calculate Class Imbalance Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e670b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight (train_in): 291.5966386554622\n"
     ]
    }
   ],
   "source": [
    "N_pos = int((y_tr == 1).sum())\n",
    "N_neg = int((y_tr == 0).sum())\n",
    "scale_pos_weight = N_neg / N_pos\n",
    "\n",
    "print(\"scale_pos_weight (train_in):\", scale_pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44cd1e",
   "metadata": {},
   "source": [
    "## 5. STEP 1 — Train XGBoost on train_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6471e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ricar\\anaconda3\\envs\\cpii\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [23:31:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"min_samples_leaf\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost trained on train_in.\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    \n",
    "    max_depth=7,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.6,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    eval_metric=\"aucpr\"\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_tr, y_tr)\n",
    "print(\"XGBoost trained on train_in.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2354d8",
   "metadata": {},
   "source": [
    "## 6. Evaluate on val_ood (Out-of-Distribution Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a2a0a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost – Val_OOD AP:  0.217187\n",
      "XGBoost – Val_OOD AUC: 0.890508\n"
     ]
    }
   ],
   "source": [
    "val_proba_xgb = xgb_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "ap_val_xgb  = average_precision_score(y_val, val_proba_xgb)\n",
    "roc_val_xgb = roc_auc_score(y_val, val_proba_xgb)\n",
    "\n",
    "print(f\"XGBoost – Val_OOD AP:  {ap_val_xgb:.6f}\")\n",
    "print(f\"XGBoost – Val_OOD AUC: {roc_val_xgb:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d90da",
   "metadata": {},
   "source": [
    "## 7. STEP 2 — Retrain on ALL Training Data (train_in + val_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ffe5cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined TRAIN (train_in + val_ood) shape: (42087, 2048) | Positives: 149\n",
      "XGBoost retrained on TRAIN + VAL (train_in + val_ood).\n",
      "XGBoost retrained on TRAIN + VAL (train_in + val_ood).\n"
     ]
    }
   ],
   "source": [
    "X_train_all = vstack([X_tr, X_val])\n",
    "y_train_all = np.concatenate([y_tr, y_val])\n",
    "\n",
    "print(\"Combined TRAIN (train_in + val_ood) shape:\",\n",
    "      X_train_all.shape, \"| Positives:\", int(y_train_all.sum()))\n",
    "\n",
    "xgb_final = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.6,\n",
    "    scale_pos_weight=scale_pos_weight,  # still based on train_in\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    eval_metric=\"aucpr\"\n",
    ")\n",
    "\n",
    "xgb_final.fit(X_train_all, y_train_all)\n",
    "print(\"XGBoost retrained on TRAIN + VAL (train_in + val_ood).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cff44a",
   "metadata": {},
   "source": [
    "## 8. STEP 3 — Final Evaluation on test_ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae6455c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost – Test_OOD AP:  0.089750\n",
      "XGBoost – Test_OOD AUC: 0.734257\n"
     ]
    }
   ],
   "source": [
    "test_proba_xgb = xgb_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "ap_test_xgb  = average_precision_score(y_test, test_proba_xgb)\n",
    "roc_test_xgb = roc_auc_score(y_test, test_proba_xgb)\n",
    "\n",
    "print(f\"XGBoost – Test_OOD AP:  {ap_test_xgb:.6f}\")\n",
    "print(f\"XGBoost – Test_OOD AUC: {roc_test_xgb:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c48ce8",
   "metadata": {},
   "source": [
    "## 9. Create Submission File (Optional)\n",
    "\n",
    "If you have unlabeled test IDs for Kaggle submission, create the CSV here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "088ed752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncomment the code above to generate submission file\n"
     ]
    }
   ],
   "source": [
    "# Example: if you have test IDs loaded separately\n",
    "# ids_test = np.load(DATA_DIR / \"ids_test_ood.npy\")\n",
    "# \n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": ids_test,\n",
    "#     \"binds\": test_proba_xgb\n",
    "# })\n",
    "# \n",
    "# submission_dir = Path(\"../../../data/submission_of_models\")\n",
    "# submission_dir.mkdir(parents=True, exist_ok=True)\n",
    "# \n",
    "# submission_path = submission_dir / \"submission_xgboost_presplit.csv\"\n",
    "# submission.to_csv(submission_path, index=False)\n",
    "# \n",
    "# print(f\"✓ Submission saved to: {submission_path}\")\n",
    "# submission.head()\n",
    "\n",
    "print(\"Uncomment the code above to generate submission file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
